\documentclass[12pt,a4paper]{report}

\setlength\textwidth{145mm}
\setlength\textheight{247mm}
\setlength\oddsidemargin{15mm}
\setlength\evensidemargin{15mm}
\setlength\topmargin{0mm}
\setlength\headsep{0mm}
\setlength\headheight{0mm}


\usepackage[utf8]{inputenc}
\usepackage{qtree}

\usepackage[vlined]{algorithm2e}
%% \usepackage{algpseudocode}
\usepackage{framed}

\usepackage{xspace}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}


\newcommand{\Lets}{Let us }
\newcommand{\lterm}{$\lambda$-term\xspace}
\newcommand{\lterms}{$\lambda$-terms\xspace}

\newcommand{\turst}[3]{$#1 \vdash #2 : #3$\xspace}
\newcommand{\GMS}{\turst{\Gamma}{M}{\sigma}}


\newcommand{\Pseudokod}[2]{
	\begin{framed}
	\begin{algorithm}[H]
		\DontPrintSemicolon
		\SetKwProg{Fn}{Algorithm}{}{}
		\Fn{#1}{#2}
	\end{algorithm}
	\end{framed}
}


%% Balíček hyperref, kterým jdou vyrábět klikací odkazy v PDF,
%% ale hlavně ho používáme k uložení metadat do PDF (včetně obsahu).
%% POZOR, nezapomeňte vyplnit jméno práce a autora.
%\usepackage[ps2pdf,unicode]{hyperref}   % Musí být za všemi ostatními balíčky
%\hypersetup{pdftitle=Typed Functional Genetic Programming}
%\hypersetup{pdfauthor=Tomáš Křen}

% Tato makra přesvědčují mírně ošklivým trikem LaTeX, aby hlavičky kapitol
% sázel příčetněji a nevynechával nad nimi spoustu místa. Směle ignorujte.
\makeatletter
\def\@makechapterhead#1{
  {\parindent \z@ \raggedright \normalfont
   \Huge\bfseries \thechapter. #1
   \par\nobreak
   \vskip 20\p@
}}
\def\@makeschapterhead#1{
  {\parindent \z@ \raggedright \normalfont
   \Huge\bfseries #1
   \par\nobreak
   \vskip 20\p@
}}
\makeatother


\newcommand\Vtextvisiblespace[1][.3em]{%
  \mbox{\kern.06em\vrule height.3ex}%
  \vbox{\hrule width#1}%
  \hbox{\vrule height.3ex}}

\title{Typed Functional Genetic Programming}
\author{Tomáš Křen}
\date{Prague 2013}

\begin{document}

% Trochu volnější nastavení dělení slov, než je default.
\lefthyphenmin=2
\righthyphenmin=2

%%% Titulní strana práce

\pagestyle{empty}
\begin{center}

\large

Charles University in Prague 

\medskip

Faculty of Mathematics and Physics

\vfill

{\bf\Large MASTER THESIS}

\vfill

%%% \centerline{\mbox{\includegraphics[width=60mm]{../img/logo.eps}}}

%\begin{figure}[!ht]
%  \centering
%  \includegraphics{logo.eps}
%  \caption{Default}\label{fig:default}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stačí todle odkomentovat a dát nahoře LaTeX (F2) , pak DVI->PDF (F9)  a pak View PDF
%\includegraphics[scale=0.5]{logo.eps}
\includegraphics[scale=0.15]{logomff.png}

\vfill
\vspace{5mm}

{\LARGE Tomáš Křen}

\vspace{15mm}

% Název práce přesně podle zadání
{\LARGE\bfseries Typed Functional Genetic Programming}

\vfill

% Název katedry nebo ústavu, kde byla práce oficiálně zadána
% (dle Organizační struktury MFF UK)
%%%%Name of the department or institute
%Department of Theoretical Computer Science and Mathematical Logic\\
%{\small Department of Theoretical Computer Science and Mathematical Logic} \\
{\fontsize{0.46cm}{1em}\selectfont 
Department of Theoretical Computer Science and Mathematical Logic}

\vfill

\begin{tabular}{rl}

Supervisor of the master thesis: & RNDr. Petr Pudlák, Ph.D. \\
\noalign{\vspace{2mm}}
Study programme: & Theoretical Computer Science \\ %Teoretická informatika \\
\noalign{\vspace{2mm}}
Specialization: & 
%Neprocedurální programování a umělá inteligence \\
{\fontsize{0.3cm}{1em}\selectfont 
%Neprocedurální programování a umělá inteligence} \\
Non-Procedural Programming and Artificial Intelligence} \\
\end{tabular}

\vfill

% Zde doplňte rok
Prague 2013

\end{center}

\newpage

%%% Následuje vevázaný list -- kopie podepsaného "Zadání diplomové práce".
%%% Toto zadání NENÍ součástí elektronické verze práce, nescanovat.

%%% Na tomto místě mohou být napsána případná poděkování (vedoucímu práce,
%%% konzultantovi, tomu, kdo zapůjčil software, literaturu apod.)

%% on tam měl %% \openright

\noindent
Dedication.

\newpage

%%% Strana s čestným prohlášením k diplomové práci

\vglue 0pt plus 1fill

\noindent
I declare that I carried out this master thesis independently, and only with the cited
sources, literature and other professional sources.

\medskip\noindent
I understand that my work relates to the rights and obligations under the Act No.
121/2000 Coll., the Copyright Act, as amended, in particular the fact that the Charles
University in Prague has the right to conclude a license agreement on the use of this
work as a school work pursuant to Section 60 paragraph 1 of the Copyright Act.

\vspace{10mm}

\hbox{\hbox to 0.5\hsize{%
In ........ date ............
\hss}\hbox to 0.5\hsize{%
signature of the author
\hss}}

\vspace{20mm}
\newpage


%%% Povinná informační strana diplomové práce

\vbox to 0.5\vsize{
\setlength\parindent{0mm}
\setlength\parskip{5mm}

Název práce:
Název práce
% přesně dle zadání

Autor:
Jméno a příjmení autora

Katedra:  % Případně Ústav:
Název katedry či ústavu, kde byla práce oficiálně zadána
% dle Organizační struktury MFF UK

Vedoucí diplomové práce:
Jméno a příjmení s tituly, pracoviště
% dle Organizační struktury MFF UK, případně plný název pracoviště mimo MFF UK

Abstrakt:
% abstrakt v rozsahu 80-200 slov; nejedná se však o opis zadání diplomové práce

Klíčová slova:
% 3 až 5 klíčových slov

\vss}\nobreak\vbox to 0.49\vsize{
\setlength\parindent{0mm}
\setlength\parskip{5mm}

Title:
% přesný překlad názvu práce v angličtině

Author:
Jméno a příjmení autora

Department:
Název katedry či ústavu, kde byla práce oficiálně zadána
% dle Organizační struktury MFF UK v angličtině

Supervisor:
Jméno a příjmení s tituly, pracoviště
% dle Organizační struktury MFF UK, případně plný název pracoviště
% mimo MFF UK v angličtině

Abstract:
% abstrakt v rozsahu 80-200 slov v angličtině; nejedná se však o překlad
% zadání diplomové práce

Keywords:
% 3 až 5 klíčových slov v angličtině

\vss}

\newpage


\tableofcontents	
	
%\chapter{Introduction}
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
	
\chapter{Definitions}
	
	\Lets first say some basic definitions.

\section{Genetic Programming}

\textit{Genetic programming} (GP) is a technique inspired by biological evolution
that for a given problem tries to find computer programs able to solve that problem. 
GP was developed by John Koza \cite{koza92} in 1992.

A problem to be solved is given to GP in a form of \textit{fitness function}. 
Fitness function is a function which takes computer program as its input and 
returns numerical value called \textit{fitness} as output. 
The bigger fitness of a computer program is, the better solution of a problem.

GP maintains a collection of computer programs called \textit{population}. 
A member of population is called \textit{individual}. 
By running GP algorithm evolution of those individuals is performed.

Individuals are computer program \textit{expressions} kept as \textit{syntactic trees}. 
Basically those trees are rooted trees with a function symbol in each internal node 
and with constant symbol or variable symbol in each leaf node. 
Number of child nodes for each internal node corresponds to the number of arguments of a function whose
symbol is in that node.

Another crucial input besides fitness function is a collection of \textit{building blocks}.
It is collection of symbols (accompanied with an information about number of arguments).
Those symbols are used to construct trees representing individuals.  
\\\\
\Lets describe GP algorithm briefly:

At the beginning initial population is generated from building blocks randomly.

A step of GP algorithm is stochastic transformation of the current population into 	
the next population.

This step consists of two sub steps\footnote{TODO : Technically it is done in a little  
bit different fashion which is equivalent.}:
\begin{itemize} 
	\item Selection of \textit{parents} for individuals of the next population based on the fitness.
	      The bigger fitness of an individual of the current population is, 
	      the better chance of success being selected as parent it has.  
	\item Application of genetic operators (such as \textit{crossover}, 
	      \textit{reproduction} and \textit{mutation}) 
		  on parent individuals producing new individuals of the next population.  
\end{itemize}	  
This transformation is repeatedly applied for a predefined number of steps (which is called 
number of \textit{generations}) or until some predefined criterion is met.	
\\\\
\Lets now look on GP at more detail. Here is pseudocode for GP algorithm:

\Pseudokod{GP(fitnessFun,buildingBlocks,numGens,popSize,probabs)}{
	$gen \leftarrow$ 0 \;
	$pop \leftarrow generateInitialPopuletion( buildingBlocks ) $ \;
	($popWithFitnesses,terminate) \leftarrow$ evaluate($fitnessFun$, $pop$) \; 	
	
	\While{ $gen < numGens$ $\wedge$ $\neg terminate$  }{
  	
	
	$newPop \leftarrow$ empty population \;
	$i \leftarrow 0$ \;
	
	\While{ $i < popSize$ }{
		$op \leftarrow probabilisticallySelectOperation(probabs)$ \;		
		\Switch{op}{
			\Case{Crossover}{
				$indiv1 \leftarrow$ selection( $popWithFitnesses$ ) \;
				$indiv2 \leftarrow$ selection( $popWithFitnesses$ ) \;
				($child1$,$child2$) = crossover( $indiv1$ , $indiv2$ ) \;
				$newPop$.insert( $child1$ ) \;
				$newPop$.insert( $child2$ ) \;
				$i \leftarrow i + 2$ \;
			}
			\Case{Reproduction}{
				$indiv \leftarrow$ selection( $popWithFitnesses$ ) \;
				$newPop$.insert( $indiv$ ) \;
				$i \leftarrow i + 1$ \;
			}
			\Case{Mutation}{
				$indiv \leftarrow$ selection( $popWithFitnesses$ ) \;
				$mutant \leftarrow$ mutate( $indiv$ ) \;
				$newPop$.insert( $mutant$ ) \;
				$i \leftarrow i + 1$ \;			
			}		
		}
	}
	
	$pop \leftarrow newPop$  \;
	$gen \leftarrow gen + 1$ \;
	\;
	($popWithFitnesses,terminate) \leftarrow$ evaluate($fitnessFun$, $pop$) \; 
 }
 \Return pop \;
}

In order to clarify the code let us describe in greater detail inputs and
contained procedures
generateInitialPopuletion(),
evaluate(),
probabilisticallySelectOperation(),
selection(),
crossover() 
and mutation().






	\subsection{Input}
	\subsection{Output}
	\subsection{GP algorithm}
		\subsubsection{Generating initial population}
		\subsubsection{Selection}
		\subsubsection{Crossover}
		\subsubsection{Reproduction}
		\subsubsection{Mutation}


    ...
	\\\\
	\textbf{TODO}
	\begin{itemize} 
		\item TALK ABOUT GP is part of EA etc. and maybe define the GP by defining EA and then
		      specifying the differences or something like that...    
		\item History, citations, etc ....
		\item ten algoritmus v kozovi dělá "Designate Result" já tam vracim poslední populaci
	\end{itemize}	  
		
\section{Lambda term}
\label{deflam}
	
	Let $V$ be set of {\it variable names}.  \\* 
	Let $C$ be set of {\it constant names}.	 \\*		
	Then $\Lambda$ is set of {\it \lterms} inductively defined as follows:
	
	\begin{align*}
		 x   \in V \cup C          &\Rightarrow     x   \in \Lambda \\
		 M,N \in \Lambda           &\Rightarrow ( M N ) \in \Lambda \\
		 x   \in V , M \in \Lambda &\Rightarrow ( \lambda x . M ) \in \Lambda 
	\end{align*} 

	\textbf{TODO} 
	\begin{itemize} 
		\item TALK ABOUT "parenthesis" conventions (and packing of lambda abstractions).
		\item BETTER SPECIFICATION $V$ is infinite spočetná (?countable)
	\end{itemize}
	
\section{Type}
\label{deftype}

	Let $A$ be set of {\it atomic type names}. \\*
	Then $\mathbb{T}$ is set of {\it types} inductively defined as follows:
	
	\begin{align*}
	\alpha      \in A          &\Rightarrow     \alpha   \in \mathbb{T} \\
	\sigma,\tau \in \mathbb{T} &\Rightarrow ( \sigma \rightarrow  \tau ) \in \mathbb{T} 
	\end{align*} 

\textbf{TODO} 
\begin{itemize}
	\item TALK ABOUT $\tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$ 
	\item TALK ABOUT arrow/parenthesis conventions. 
\end{itemize}
	
	
\section{Statement of a form $M : \sigma$}

	Let $\Lambda$ be set of {\it \lterms}. \\*
	Let $\mathbb{T}$ be set of {\it types}.       \\*
	A {\it statement} $M : \sigma$ is a pair $(M,\sigma) \in \Lambda \times \mathbb{T}$. \\*
	$M : \sigma$ is vocalized as {\it "$M$ has type $\sigma$"}.\footnote{ 
	$M : \sigma$ can be also imagined as $M \in \sigma$ } \\*
	The type $\sigma$ is the {\it predicate} and the term $M$ is the
	{\it subject} of the statement.  
	
\section{Context}

	Let $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right)$. 
	($\Gamma$ is a set of {\it statements} of a form $M : \sigma$.)	\\*
	Then $\Gamma$ is {\it context} if it obeys following 
	conditions\footnote{
	The $\pi_1$ corresponds to the projection of the first component of the Cartesian product.
	}:
	\begin{align*}
		 \forall (x,\sigma) \in \Gamma &: x \in V \cup C \\
		 \forall s_1,s_2 \in \Gamma &: s_1 \neq s_2 \Rightarrow \pi_1(s_1) \neq \pi_1(s_2)
    \end{align*}
    
	In other words context is a set of statements with distinct variables or constants as subjects.
	\\\\
	\textbf{TODO:} TALK ABOUT Context represents library/building blocks.
	
	
	
\section{Statement of a form \GMS}

	By writing \GMS we say 
	{\it statement $M : \sigma$ is derivable from context $\Gamma$ }.

	We construct valid statements of form \GMS by using inference rules.
	
		
\section{Inference rule}		
	
	Basically speaking, inference rules are used for deriving statements of a form 
	\GMS from yet derived statements of such a form.
	Those inference rules are written in the following form:
	
	\begin{equation*}
		\frac{\Gamma_1 \vdash M_1 : \sigma_1 \qquad
			  \Gamma_2 \vdash M_2 : \sigma_2 \quad
			  \dotsm \quad
		      \Gamma_n \vdash M_n : \sigma_n}
		     {\Gamma_{n+1} \vdash M_{n+1} : \sigma_{n+1}}
	\end{equation*}	
	
	Suppose we have yet derived statements 
	$\Gamma_1 \vdash M_1 : \sigma_1 ,
	 \Gamma_2 \vdash M_2 : \sigma_2 ,
	 \dots ,
	 \Gamma_n \vdash M_n : \sigma_n$. 
	It allows as to use the inference rule to derive statement
	\mbox{ $\Gamma_{n+1} \vdash M_{n+1} : \sigma_{n+1}$ }.
	 
	For deriving statements including types of a form 
	$(\sigma \rightarrow \tau)$ are essential those two 
	inference rules:
	
	\begin{equation*}
		\frac{\Gamma \vdash M : \sigma \rightarrow \tau \qquad
			  \Gamma \vdash N : \sigma }
		     {\Gamma \vdash (M N) : \tau }
	\end{equation*}	
	
	\begin{equation*}
		\frac{\Gamma \cup \{ ( x,\sigma ) \} \vdash M : \tau }
		     {\Gamma \vdash (\lambda x . M) : \sigma \rightarrow \tau }
	\end{equation*}		 
	 
	This kind of inference rules allows us to derive new statements from yet derived statements, but 
	what if we do not have any statement yet? 
	For this purpose we have other kinds of inference rules such as {\it axiom} inference rule:   
	
	\begin{equation*}
		\frac{( x , \sigma )  \in \Gamma}
		     {\Gamma \vdash x : \sigma}
	\end{equation*}	
	
	\Lets consider an example statement of a form \GMS :
	
	\[
		\{\} \vdash (\lambda f . (\lambda x . (f x) )) : 
		(\sigma \rightarrow \tau) \rightarrow ( \sigma \rightarrow \tau ) 
	\]
		
	This statement is derived as follows: 
	
	\begin{equation*}
	\dfrac{
		\dfrac{ (f,\sigma \rightarrow \tau) \in \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \}  }
		     { \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash f : \sigma \rightarrow \tau }
		\qquad
		\dfrac{ (x,\sigma) \in \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \}  }
		     { \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash x : \sigma }
		 }
		 {
			\dfrac{		 	
		 		\{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash (f x) : \tau
		 	}{
				\dfrac{\{ (f,\sigma \rightarrow \tau) \} \vdash (\lambda x . (f x) ) : 
				\sigma \rightarrow \tau}
				{ \{ \} \vdash (\lambda f . (\lambda x . (f x) ) ) 
				  : (\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau) }
		 	}
		 }
	\end{equation*}		
	
\section{Term generating grammar}

Inference rules are good for deriving statements of a form \GMS, but our
goal is slightly different; we would like to generate many \lterms M for a given type 
$\sigma$ and context $\Gamma$.

Our approach will be to take each inference rule and transform it to a rule of term generating
grammar. With this term generating grammar it will be much easier to reason about generating 
\lterms.
	
It won't be a grammar in classical sense because we will be operating with infinite sets of
nonterminal symbols and rules. \footnote{TODO : mention terminal symbols - situation around 
variables and their construction with ' symbol.}

Let $Non = Type \times Context $ be our {\it nonterminal} set. 
So for every $i \in Non$ is $i = (\sigma_i , \Gamma_i )$.

\Lets consider each relevant inference rule and its corresponding grammar rule.

First inference rule is {\it implication elimination} also known as 
{\it modus ponens}: 
\[
	\frac{\Gamma \vdash M : \sigma \rightarrow \tau \qquad
		  \Gamma \vdash N : \sigma }
	     {\Gamma \vdash (M N) : \tau }
\]
\\
For every $\sigma, \tau \in \mathbb{T}$ and for every {\it context} 
$\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right)$ there is a grammar rule of a form\footnote{ 
Terminal symbols for parenthesis and normally {\it space} now \textvisiblespace \quad (for {\it function application} operator) are visually highlighted. }: 
\[	
	( \tau , \Gamma )  \longmapsto
	\bigg( ( \sigma \rightarrow \tau , \Gamma ) 
	  \mbox{ \Vtextvisiblespace[1em] } ( \sigma , \Gamma ) \bigg)
\]
\\

Second inference rule is {\it implication introduction}: 
\[
	\frac{\Gamma \cup \{ ( x,\sigma ) \} \vdash M : \tau }
	     {\Gamma \vdash (\lambda x . M) : \sigma \rightarrow \tau }
\]
\\
$\forall \sigma, \tau \in \mathbb{T}$ 
$\forall${\it context} $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right) $ 
$\forall x \in V $ such that there is no $(x,\rho) \in \Gamma$ 
there is a grammar rule:
\[ 
	( \sigma \rightarrow \tau , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large $\lambda$ x . }}( \tau , \Gamma \cup \{ (x,\sigma) \} ) \quad \bigg)
\]
\\	

Third inference rule is {\it axiom}: 
\[
		\frac{( x , \sigma )  \in \Gamma}
		     {\Gamma \vdash x : \sigma}
\]
\\
$\forall \sigma \in \mathbb{T}$ 
$\forall${\it context} $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right) $ 
$\forall x \in V \cup C $ such that $(x,\sigma) \in \Gamma$ 
there is a grammar rule:
\[ 
	( \sigma , \Gamma )  \longmapsto \mbox{ {\Large x}}
\]
\\

We will demonstrate \lterm generation on example. 
Again on $(\lambda f . (\lambda x . (f x) ))$. 
We would like to generate \lterm of a type 
$(\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau)$
with $\Gamma = \{\}$.
\begin{align*}
	& ((\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau),\{\}) \\ 
	\longmapsto & \Big( \mbox{ {\Large $\lambda$f.}}
	  ( \sigma \rightarrow \tau , \{ (f,\sigma \rightarrow \tau) \} ) 
	~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}
	  	 	( \tau , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) 
		~ \Big)  	 
	~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  ( \sigma \rightarrow \tau , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  ( \sigma , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} )  \Big) 
		~ \Big)  	 
	 ~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  \mbox{ {\Large f}} 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  ( \sigma , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) \Big) 
		~ \Big)  	 
	~ \Big)		
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  \mbox{ {\Large f}} 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  \mbox{{\Large x}} \Big) 
		~ \Big)  	 
	~ \Big)
\end{align*}

\subsection{"Barendregt-like" inference and grammar rules}
\label{barlike}

Inference rule 1: 
\[
	\frac{\Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} \vdash M : \alpha }
	     {\Gamma \vdash (\lambda x_1 \dots x_n . M) : 
	     \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha }
\]
\\
Proof of correctness:
\[
	\dfrac{
		\dfrac
		 {\Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} \vdash M : \alpha}
		 {\dfrac
		   {\Gamma \cup \{ (x_1,\tau_1),\dots,(x_{n-1},\tau_{n-1})\} \cup 
		                \{(x_n,\tau_n) \} \vdash M : \alpha}
		   {\dfrac{\Gamma \cup \{ (x_1,\tau_1),\dots,(x_{n-1},\tau_{n-1})\}  
		                \vdash (\lambda x_n . M) : \tau_n \rightarrow \alpha}
				  { \vdots }		   
		   }
		 }		 
	 }
	     {\Gamma \vdash (\lambda x_1 \dots x_n . M) : 
	     \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha }
\]
\\
... there is a grammar rule:
\[ 
	( \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large 
	$\lambda x_1 \dots x_n .$ 
	}}( \alpha , \Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} ) \quad \bigg)
\]
\\

Inference rule 2: 
\[
	\frac{ (f , \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha ) \in \Gamma \qquad
	       \Gamma \vdash M_1 : \rho_1 \quad
	       \dotsm \quad
	       \Gamma \vdash M_m : \rho_m        
	      }
	     {\Gamma \vdash (f M_1 \dots M_m) : \alpha}
\]
\\
Proof of correctness (\textbf{TODO REPAIR} Conceptually it is ok but there is sazba-bug somewhere): 
\[
   \dfrac
     {\dfrac
      {\dfrac
       {\dfrac         
         {\dfrac  
          {\dfrac
           {\boxed{(f , \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha ) \in \Gamma}}
           {\Gamma \vdash f : \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha}
           \quad
           \boxed{\Gamma \vdash M_1 : \rho_1} }
          {\Gamma \vdash (f M_1) : \rho_2 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha }
          }{\vdots} 
         \quad 
         \ddots }
       {\Gamma \vdash (f M_1 \dots M_{m-2}) : \rho_{m-1} \rightarrow \rho_m \rightarrow \alpha}
       \quad
       \boxed{\Gamma \vdash M_{m-1} : \rho_{m-1}}  }
      {\Gamma \vdash (f M_1 \dots M_{m-1}) : \rho_m \rightarrow \alpha}       
      \quad 
      \boxed{\Gamma \vdash M_m : \rho_m} }
	 {\Gamma \vdash (f M_1 \dots M_m) : \alpha}
\]
\\
... there is a grammar rule:
\[ 
	( \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large f }}
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_1 , \Gamma )
	  \mbox{ \Vtextvisiblespace[1em] } 
	  \dots
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_m , \Gamma )
	  \quad \bigg)
\]
\\\\
\textbf{TODO} 
\begin{itemize}
	\item SHOW correctness of those inference rules by composing them of 
		  $E^{\rightarrow}$, $I^{\rightarrow}$ and \textit{axiom}.
	\item SHOW more examples of inference rules transformed into grammar rules.
	\item DESCRIBE general algorithm for this transformation.
	\item TALK ABOUT $\tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$ 
	\item TALK ABOUT $\beta \eta$-normal form which is generated by this method.
\end{itemize}



\section{Inhabitation tree}

Now we will introduce \textit{Inhabitation tree}, structure slightly different from
\textit{Inhabitation machine}, which was introduced in \cite{barendregt10} by Henk Barendregt.
We can think about Inhabitation tree as about unfolded Inhabitation machine.
The motivation for using Inhabitation trees is belief that it will help us 
reason about generation of \lterms 
of a given type $\sigma$ and with a given context $\Gamma$.  

\subsection{Definition of Inhabitation tree}

\textit{Inhabitation tree} is a \textit{rooted tree}, possibly infinite. 
It has two types of nodes:

\begin{samepage}
\begin{itemize}
  \item Type nodes   
  			- containing type $\sigma \in \mathbb{T}$ 
  			- aka "OR-node" , Nonterminal-node. 
  \item Symbol nodes 
  			%- containing $ x^{*} \in \mathfrak P \left(V\right) -blobost pač ordered $ or $c \in C$
  			- containing "$\lambda$-head" (nonempty finite sequence of variable names) or constant
  			  name. 
  			- aka "AND-node" , Terminal-node.
\end{itemize}
\end{samepage}

We construct Inhabitation tree for given type $\sigma$ and context $\Gamma$.\\
We will define Inhabitation tree by describing its construction for a given $(\sigma,\Gamma)$.
Notice that it will closely follow the rules from \ref{barlike}:

\begin{itemize}
\item The root of Inhabitation tree for $(\sigma,\Gamma)$ is 
      \textit{type node} with $\sigma$ as type.
\item All \textit{type nodes} have as child nodes only \textit{symbol nodes}. 
\item And all \textit{symbol nodes} have as child nodes only \textit{type nodes}. 
\end{itemize}

Now we will resolve the child nodes of the root node.

There are two cases of $\sigma$ (recall \ref{deftype}): 
\begin{description}
	\item[Atomic type] 
		$\sigma = \alpha $ where $\alpha \in A$. 
	\item[Function type] 
		$\sigma = \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$
		where $n \geq 1, \alpha \in A$.
\end{description}

First case \textbf{Atomic type} --- i.e., $\sigma = \alpha$ where $\alpha \in A$:\\
For every $(f,\rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha) \in \Gamma$
where $\alpha \in A$ there is a child \textit{symbol node} of the root containing constant name $f$.
This symbol node containing $f$ has $m$ child subtrees corresponding to Inhabitation trees for 
$(\rho_1,\Gamma),\dots,(\rho_n,\Gamma)$.   

~

Compare this case with corresponding grammar rule:
\[ 
	( \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large f }}
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_1 , \Gamma )
	  \mbox{ \Vtextvisiblespace[1em] } 
	  \dots
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_m , \Gamma )
	  \quad \bigg)
\]

Second case \textbf{Function type} --- i.e., 
$\sigma = \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$
where $n~\geq~1, \alpha~\in~A$:\\
For every  $i \in \{1,\dots,n\}$ we create new \textit{variable name} $x_i$ which is not yet included in context $\Gamma$ as variable or constant name.
 
There is one and only one child \textit{symbol node} of the root containing "$\lambda$-head" 
$\lambda x_1 \dots x_n$ which stands for sequence of variable names $(x_1,\dots,x_n)$.
This symbol node containing $\lambda x_1 \dots x_n$
has one and only one child subtree corresponding to Inhabitation trees for 
$(\alpha,\Gamma \cup \{ (x_1,\tau_1) , \dots , (x_n,\tau_n) \})$.   

~

Compare this case with corresponding grammar rule:
\[ 
	( \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large 
	$\lambda x_1 \dots x_n .$ 
	}}( \alpha , \Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} ) \quad \bigg)
\]
~\\
\Lets consider following $(\sigma,\Gamma)$ as a simple example:

\begin{align*}
\sigma =& ~ \mathbb{B} \rightarrow  \mathbb{B} \rightarrow  \mathbb{B} \\ 
\Gamma =& \{ ~ true : \mathbb{B}  \\
        &  , ~ nand :  \mathbb{B} \rightarrow \mathbb{B} \rightarrow \mathbb{B} ~ \}
\end{align*}

This particular $(\sigma,\Gamma)$ results in the following tree:\\

\Tree
[.\text{ $\mathbb{B} \rightarrow \mathbb{B} \rightarrow \mathbb{B}$ }  
	[.\textbf{$\lambda$x_1 x_2 } 
		[.\text{ $\mathbb{B}$ } 
			\textbf{true}  
			[.\textbf{nand} 
				\qroof{ ~~ $\dotsb$ ~~ }.\text{ $\mathbb{B}$ }
				\qroof{ ~~ $\dotsb$ ~~ }.\text{ $\mathbb{B}$ } 
			]
			\textbf{x_1}
			\textbf{x_2}
		]
	]
]

~

Second example features our well known example:

\begin{align*}
\sigma =& ~ (\sigma \rightarrow \tau) \rightarrow \sigma \rightarrow \tau \\ 
\Gamma =& \{ \}
\end{align*}

Which results in following tree:

\Tree
[.\text{ $(\sigma \rightarrow \tau) \rightarrow \sigma \rightarrow \tau $ } 
	[.\textbf{$\lambda$ f x }	
		[.\text{ $\tau$ }		
			[.\textbf{f} 
				[.\text{ $\delta$ }
					\textbf{x}					
				]
			]
		]
	]
] 


\subsection{And-or tree and searching in Inhabitation tree}
\Lets consider following definition of 
\textit{And-or tree}\footnote{
\textbf{TODO}: Mention that on WIKI there is more general definition, but 
for our purposes is this one sufficient.}:

\textit{And-or tree} is a rooted tree where each node is labeled as either \textit{and-node} 
or\footnote{xor} \textit{or-node}.

By \textit{solving} And-or tree $T$ we mean finding $T'$
subtree of $T$ such that it follows these conditions: 
\begin{itemize}
	\item The root of $T'$ is the root of $T$.
	\item Each \textit{and-node} in $T'$ has all the child nodes as in $T$.
	\item Each \textit{or-node}  in $T'$ has precisely one child 
	      node.\footnote{\textbf{TODO}: MENTION why precisely one 
	      and not at least one ..or CHANGE the def. }   
\end{itemize}
~
\Lets now consider following labeling of Inhabitation tree: 

\begin{itemize}
  \item \textbf{Type nodes}   are labeled as \textbf{or-nodes}.   
  \item \textbf{Symbol nodes} are labeled as \textbf{and-nodes}.
\end{itemize}

This labeling has following justification: 

Selection of exactly one
child node in \textit{type node} corresponds to selection of exactly one
grammar rule in order to rewrite nonterminal symbol.  

Selection of all the child nodes in \textit{symbol node} corresponds to 
rewriting all the nonterminal symbols in string that is being generated.  

The motivation for defining \textit{solving} of a And-or tree the way we did is that
a found tree $T'$ corresponds to generated \lterm. 
In order to understand this correspondence let's now talk about various tree representations
of \lterms.

\subsection{Tree representations of \lterms}

From the definition of \lterm (\ref{deflam}) we can straightforwardly derive 
the classical tree representation for \lterms. Term M is translated into tree $T[M]$ by following rules:

\begin{itemize}
	\item $x \in V \cup C$ translates into \textit{leaf} $x$.
	\item $(M N)$ translates into tree\\
		\Tree
			[.@	
		 		\text{$T[M]$}
		 		\text{$T[N]$}		 			
			] 
	\item $\lambda x . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x$}	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

We can enhance this representation by compressing consecutive lambda abstractions into one
tree node like this: 

\begin{itemize}
	\item $\lambda x_1 \dots x_n . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x_1 \dots x_n$ }	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

As this representation comes directly from definition it is evident 
that it covers all possible \lterms.

For representing expressions as trees it is however more common use a little different
representation. It will also be the representation suitable for showing 
that \textit{solving} Inhabitation tree generates wanted \lterm.

\begin{itemize}
    \item $x \in V \cup C$ translates into \textit{leaf} $x$.
	\item $(f M_1 M_2 \dots M_n)$ where $f \in V \cup C, n \geq 1$ translates into tree\\
		\Tree
			[.f	
		 		\text{$T[M_1]$}
		 		\text{$T[M_2]$}
		 		\text{$\dots$}
		 		\text{$T[M_n]$}		 				 			
			] 
	\item $\lambda x_1 \dots x_n . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x_1 \dots x_n$ }	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

Notice that this representation does not cover all \lterms, 
e.g. $(\lambda x.x) y$ is not expressible in it. But it does not bother us.  
\\\\
\Lets now consider representation for \textit{typed \lterms}.
Straightforward approach would be to add to each node a type entry which 
would be the type of the \lterm corresponding to subtree having this
node as the root node. 

Approach more suitable for our purpose is to add a special type node above each node.
More specifically:

\Lets consider tree $t$ corresponding to a \lterm of a type
$\sigma$ with root $r$ and subtrees $s_1 , \dots , s_n$. 
Then corresponding tree $TT[t]$ for typed \lterm is 
obtained from the tree $t$ as follows:  

\begin{equation*}
\mbox{ 
TT[
\Tree
	[.r 	
	  	  \text{$s_1$}
		  \text{$s_2$}
		  \text{$\dots$}
		  \text{$s_n$}
	] 
}]=
\mbox{
\Tree
	[.\text{$\sigma$ }
	    [.r 	
	  	  \text{$TT[s_1]$}
		  \text{$TT[s_2]$}
		  \text{$\dots$}
		  \text{$TT[s_n]$}
		]	  	
	] 
}
\end{equation*}
	  	
Now we can finally put the pieces together. 
Every solution to a Inhabitation tree has this just described tree form of a typed \lterm. 
 

~\\
\textbf{TODO} 
\begin{itemize}
\item EXAMPLES of tree representations of \lterms  
\item TALK (more?) ABOUT "Barendregt-like" subsection \ref{barlike}\\
		Things about $\beta\eta$ normal form, etc.    
\end{itemize}
		

\subsection{Our approach to \textit{solving} Inhabitation machine}

\subsubsection{A* algorithm}


\subsection{Inhabitation Machine}
\textbf{TODO} 
\begin{itemize}
\item DESCRIBE Inhabitation Machine...
\end{itemize}


\section{Roadmap}
	\section{Conversion to SKI combinators}

\chapter{ Designed system }	
	\section{Top level view}
		\subsection{Comments about main source files}
			\subsubsection{ Eva.hs }
			\subsubsection{ GP\_{}Core.hs }
	\section{Term generating}
		\subsection{A* algorithm}
	\section{Crossover}
		\subsection{Finding same types}
		\subsection{Two basic options}
		Resolve problems with free variables or avoid variables completely. 
		
	\section{Mutation}
		\subsection{Using term generation}


\chapter{Problems}
	In this section will be presented usage of the system in order to solve specific problems.
		
	
		\section{Even Parity Problem}
		\section{Big Context}
		\section{Fly}
		\section{Simple Symbolic Regression}
		\section{Artificial Ant}
		\section{Boolean Alternate}
	

%\chapter{Conclusion}
\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}	
	

\begin{thebibliography}{9}


\bibitem{koza92}

  John R. Koza,
  \emph{Genetic Programming: On the Programming of Computers by Means of Natural Selection}.
  MIT Press, Cambridge, MA,
  1992. 

\bibitem{barendregt10}

  Henk Barendregt, Wil Dekkers, Richard Statman,
  \emph{Lambda Calculus With Types}.
  Cambridge University Press,
  2010. \\
  \url{http://www.cs.ru.nl/~henk/book.pdf}

\end{thebibliography}

	
	
\end{document}
