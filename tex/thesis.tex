\documentclass[12pt,a4paper]{report}

\setlength\textwidth{145mm}
\setlength\textheight{247mm}
\setlength\oddsidemargin{15mm}
\setlength\evensidemargin{15mm}
\setlength\topmargin{0mm}
\setlength\headsep{0mm}
\setlength\headheight{0mm}


\usepackage[utf8]{inputenc}
\usepackage{qtree}

\usepackage[vlined]{algorithm2e}
%% \usepackage{algpseudocode}
\usepackage{framed}

\usepackage{xspace}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}


\newcommand{\Lets}{Let us }
\newcommand{\lterm}{$\lambda$-term\xspace}
\newcommand{\lterms}{$\lambda$-terms\xspace}
\newcommand{\lhead}{$\lambda$-head\xspace}
\newcommand{\lheads}{$\lambda$-heads\xspace}


\newcommand{\turst}[3]{$#1 \vdash #2 : #3$\xspace}
\newcommand{\GMS}{\turst{\Gamma}{M}{\sigma}}


\newcommand{\EA}{EA\xspace} % TODO nahradit správnym "evoluťionar algorithms"

\newcommand{\setDots}[2]{ 
	\lbrace #1 \dots #2 \rbrace
}


\newcommand{\Pseudokod}[2]{
	\begin{framed}
	\begin{algorithm}[H]
		\DontPrintSemicolon
		\SetKwProg{Fn}{Algorithm}{}{}
		\Fn{#1}{#2}
	\end{algorithm}
	\end{framed}
}


%% Balíček hyperref, kterým jdou vyrábět klikací odkazy v PDF,
%% ale hlavně ho používáme k uložení metadat do PDF (včetně obsahu).
%% POZOR, nezapomeňte vyplnit jméno práce a autora.
%\usepackage[ps2pdf,unicode]{hyperref}   % Musí být za všemi ostatními balíčky
%\hypersetup{pdftitle=Typed Functional Genetic Programming}
%\hypersetup{pdfauthor=Tomáš Křen}

% Tato makra přesvědčují mírně ošklivým trikem LaTeX, aby hlavičky kapitol
% sázel příčetněji a nevynechával nad nimi spoustu místa. Směle ignorujte.
\makeatletter
\def\@makechapterhead#1{
  {\parindent \z@ \raggedright \normalfont
   \Huge\bfseries \thechapter. #1
   \par\nobreak
   \vskip 20\p@
}}
\def\@makeschapterhead#1{
  {\parindent \z@ \raggedright \normalfont
   \Huge\bfseries #1
   \par\nobreak
   \vskip 20\p@
}}
\makeatother


\newcommand\Vtextvisiblespace[1][.3em]{%
  \mbox{\kern.06em\vrule height.3ex}%
  \vbox{\hrule width#1}%
  \hbox{\vrule height.3ex}}

\title{Typed Functional Genetic Programming}
\author{Tomáš Křen}
\date{Prague 2013}

\begin{document}

% Trochu volnější nastavení dělení slov, než je default.
\lefthyphenmin=2
\righthyphenmin=2

%%% Titulní strana práce

\pagestyle{empty}
\begin{center}

\large

Charles University in Prague 

\medskip

Faculty of Mathematics and Physics

\vfill

{\bf\Large MASTER THESIS}

\vfill

%%% \centerline{\mbox{\includegraphics[width=60mm]{../img/logo.eps}}}

%\begin{figure}[!ht]
%  \centering
%  \includegraphics{logo.eps}
%  \caption{Default}\label{fig:default}
%\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stačí todle odkomentovat a dát nahoře LaTeX (F2) , pak DVI->PDF (F9)  a pak View PDF
%\includegraphics[scale=0.5]{logo.eps}
\includegraphics[scale=0.15]{logomff.png}

\vfill
\vspace{5mm}

{\LARGE Tomáš Křen}

\vspace{15mm}

% Název práce přesně podle zadání
{\LARGE\bfseries Typed Functional Genetic Programming}

\vfill

% Název katedry nebo ústavu, kde byla práce oficiálně zadána
% (dle Organizační struktury MFF UK)
%%%%Name of the department or institute
%Department of Theoretical Computer Science and Mathematical Logic\\
%{\small Department of Theoretical Computer Science and Mathematical Logic} \\
{\fontsize{0.46cm}{1em}\selectfont 
Department of Theoretical Computer Science and Mathematical Logic}

\vfill

\begin{tabular}{rl}

Supervisor of the master thesis: & RNDr. Petr Pudlák, Ph.D. \\
\noalign{\vspace{2mm}}
Study programme: & Theoretical Computer Science \\ %Teoretická informatika \\
\noalign{\vspace{2mm}}
Specialization: & 
%Neprocedurální programování a umělá inteligence \\
{\fontsize{0.3cm}{1em}\selectfont 
%Neprocedurální programování a umělá inteligence} \\
Non-Procedural Programming and Artificial Intelligence} \\
\end{tabular}

\vfill

% Zde doplňte rok
Prague 2013

\end{center}

\newpage

%%% Následuje vevázaný list -- kopie podepsaného "Zadání diplomové práce".
%%% Toto zadání NENÍ součástí elektronické verze práce, nescanovat.

%%% Na tomto místě mohou být napsána případná poděkování (vedoucímu práce,
%%% konzultantovi, tomu, kdo zapůjčil software, literaturu apod.)

%% on tam měl %% \openright

\noindent
Dedication.

\newpage

%%% Strana s čestným prohlášením k diplomové práci

\vglue 0pt plus 1fill

\noindent
I declare that I carried out this master thesis independently, and only with the cited
sources, literature and other professional sources.

\medskip\noindent
I understand that my work relates to the rights and obligations under the Act No.
121/2000 Coll., the Copyright Act, as amended, in particular the fact that the Charles
University in Prague has the right to conclude a license agreement on the use of this
work as a school work pursuant to Section 60 paragraph 1 of the Copyright Act.

\vspace{10mm}

\hbox{\hbox to 0.5\hsize{%
In ........ date ............
\hss}\hbox to 0.5\hsize{%
signature of the author
\hss}}

\vspace{20mm}
\newpage


%%% Povinná informační strana diplomové práce

\vbox to 0.5\vsize{
\setlength\parindent{0mm}
\setlength\parskip{5mm}

Název práce:
Název práce
% přesně dle zadání

Autor:
Jméno a příjmení autora

Katedra:  % Případně Ústav:
Název katedry či ústavu, kde byla práce oficiálně zadána
% dle Organizační struktury MFF UK

Vedoucí diplomové práce:
Jméno a příjmení s tituly, pracoviště
% dle Organizační struktury MFF UK, případně plný název pracoviště mimo MFF UK

Abstrakt:
% abstrakt v rozsahu 80-200 slov; nejedná se však o opis zadání diplomové práce

Klíčová slova:
% 3 až 5 klíčových slov

\vss}\nobreak\vbox to 0.49\vsize{
\setlength\parindent{0mm}
\setlength\parskip{5mm}

Title:
% přesný překlad názvu práce v angličtině

Author:
Jméno a příjmení autora

Department:
Název katedry či ústavu, kde byla práce oficiálně zadána
% dle Organizační struktury MFF UK v angličtině

Supervisor:
Jméno a příjmení s tituly, pracoviště
% dle Organizační struktury MFF UK, případně plný název pracoviště
% mimo MFF UK v angličtině

Abstract:
% abstrakt v rozsahu 80-200 slov v angličtině; nejedná se však o překlad
% zadání diplomové práce

Keywords:
% 3 až 5 klíčových slov v angličtině

\vss}

\newpage


\tableofcontents	
	
%\chapter{Introduction}
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
	
\chapter{Definitions}
	
	\Lets first say some basic definitions.

\section{Genetic Programming}

\textit{Genetic programming} (GP) is a technique inspired by biological evolution
that for a given problem tries to find computer programs able to solve that problem. 
GP was developed by John Koza \cite{koza92} in 1992.

A problem to be solved is given to GP in a form of \textit{fitness function}. 
Fitness function is a function which takes computer program as its input and 
returns numerical value called \textit{fitness} as output. 
The bigger fitness of a computer program is, the better solution of a problem.

GP maintains a collection of computer programs called \textit{population}. 
A member of population is called \textit{individual}. 
By running GP algorithm evolution of those individuals is performed.

Individuals are computer program \textit{expressions} kept as \textit{syntactic trees}. 
Basically those trees are rooted trees with a function symbol in each internal node 
and with constant symbol or variable symbol in each leaf node. 
Number of child nodes for each internal node corresponds to the number of arguments of a function whose symbol is in that node.

Another crucial input besides fitness function is a collection of \textit{building blocks}.
It is collection of symbols (accompanied with an information about number of arguments).
Those symbols are used to construct trees representing individuals.  
\\\\
\Lets describe GP algorithm briefly:

At the beginning initial population is generated from building blocks randomly.

A step of GP algorithm is stochastic transformation of the current population into 	
the next population.

This step consists of two sub steps\footnote{TODO : Technically it is done in a little  
bit different fashion which is equivalent.}:
\begin{itemize} 
	\item Selection of \textit{parents} for individuals of the next population based on the fitness.
	      The bigger fitness of an individual of the current population is, 
	      the better chance of success being selected as parent it has.  
	\item Application of genetic operators (such as \textit{crossover}, 
	      \textit{reproduction} and \textit{mutation}) 
		  on parent individuals producing new individuals of the next population.  
\end{itemize}	  
This transformation is repeatedly applied for a predefined number of steps (which is called 
number of \textit{generations}) or until some predefined criterion is met.	
\\\\
\Lets now look on GP at more detail. 


\subsection{Program trees}

In GP programs are represented as expressions. \Lets define expression inductively:

\begin{itemize}
	\item Constant\footnote{By constants we also mean procedures with zero  	
		  arguments.} or variable symbol $s$ is expression.
	\item Let there be a function with symbol $f$ which has $n$ arguments. 
	      And let there be expressions $e_{1}, ..., e_{n}$. 
	      Then ( $f$ $e_{1}$ ... $e_{n}$ ) is expression
	      \footnote{This notation comes from Lisp programming language, 
	      classical notation would be $f(e_{1}, ... ,e_{n})$. }.   
\end{itemize}

There is straightforward tree representation corresponding to these two cases:

\begin{itemize}
	\item One node tree $s$.
    \item \Tree
			[.$f$	
		 		\text{$t_{1}$}
		 		\text{...}
		 		\text{$t_{n}$} ]\\\\
		 Where $t_{1}, ..., t_{n}$ are trees corresponding to expressions $e_{1}, ..., e_{n}$.	   
\end{itemize}

Computer program with inputs $x_{1}, ..., x_{n}$ is realized as expression in which 
may occur variables $x_{1}, ..., x_{n}$.

\subsection{Building blocks}

Set of building blocks consists of two sets.

\begin{itemize}
	\item Terminal set $T$ : Set of symbols used as leaf nodes of 	               
	      program trees standing for constants and variables.
	\item Function set $F$ : Set of symbols used as internal nodes 
	      of program trees standing for functions.
\end{itemize}

Therefore $building$ $blocks = T \cup F$.\\

Beside symbols in $T \cup F$ there must also be 
an implementation for each symbol which is not variable. 
And for every function symbol from $F$ there must be specified 
number of arguments.\\

There is one important constrain on function implementations for functions from F:
There should be type $A$ that for every function symbol $f \in F$ the corresponding function implementation standing behind this symbol should be of a type 
$A \times ... \times A \rightarrow A$ and should be total (defined on all
combinations of inputs). And analogically for $t \in T$ being of a type A.  

Satisfying this constrain ensures that every program tree build 
from $T \cup F$ will be total.\\

We can say that the motivation behind this work is to construct system where we
eliminate this constraint. 

\subsection{Generating individual}

We will describe tree generating method used by Koza in \cite{koza92} called
\textit{ramped half-and-half}. 

\textbf{TODO!}\\
\textbf{Talk about Generating initial population}

\subsection{Selection}

In \EA there is plenty of options for selection mechanisms 
for us to choose from. Again we will describe mechanism Koza
used in his first book on GP. It is the \textit{Roulette selection}.
It uses fitness value of each individual in straightforward way to determine probability of selecting this individual.\\

Let there be $popSize$ individuals in the population.\\
And let $f_{i}$ be fitness value for individual i 
where $i \in \setDots{1}{popSize}$. 

Then $p_{i}$ probability of selection of individual $i$ is computed
as follows:

$$ p_{i} = \dfrac{ f_{i}  }{ \sum\limits_{j=1}^{popSize}{f_{j} }  } $$

\subsection{Crossover}

For Koza the most important genetic operator in GP is 
crossover. It is operator inspired by sexual reproduction
occurring in the nature. Generally speaking crossover takes
two (parent) individuals and combines theirs genomes to produce 
two possibly new (child) individuals.   

In GP the most common mutation is \textit{Subtree swapping mutation}.
This crossover randomly selects one node in each parent tree.
Two new child individuals are constructed by swapping subtrees 
which have roots in those selected nodes.\\

Example should clarify this process. Here are two parent trees with 
selected nodes in bold:

\Tree [.$ifneq$ $1$
		 	   [.\textbf{iflt} $0$ $x$ [.$-$ $0$ $x$ ] $1$ ]
		 	   [.$+$ \text{$x$} \text{$2$} ]
		 	   $1$ ]
\Tree [.$\%$ \text{$x$}
         	 [.\textbf{ifeq} \text{$1$} \text{$x$} \text{$x$} \text{$0$} ] ]\\

And here are two child trees with swapped subtrees:

\Tree [.$ifneq$ $1$
		 	   [.\textbf{ifeq} \textbf{1} \textbf{x} \textbf{x} 
		 	     \textbf{0} ]
		 	   [.$+$ \text{$x$} \text{$2$} ]
		 	   $1$ ]
\Tree [.$\%$ \text{$x$}
         	 [.\textbf{iflt} \textbf{0} \textbf{x} 
         	   [.\textbf{-} \textbf{0} \textbf{x} ] \textbf{1} ] ]\\


\subsection{Reproduction}

Reproduction is simple mechanism providing preservation of solutions
from the current population to the next one. It simply copies 
one individual to the next population.

\subsection{Mutation}

Mutation is genetic operator modifying one individual.
There are many options for mutation mechanisms 
for us to choose from. Here will be described 
\textit{Subtree generating mutation} 
witch uses mechanism for generating individuals.

This mutation randomly selects one node in the individual tree.
New mutant individual is constructed by replacement of 
subtree with root in the selected node by new generated
tree. This new tree is generated by mechanism for generating 
individuals.


\subsection{Construction of a next population}

Let $pop_{t}$ be the current population which we want to 
transform into the next population $pop_{t+1}$. 
We start by initializing $pop_{t+1}$ by empty population.

Then we iteratively fill $pop_{t+1}$ by individuals 
returned by genetic operators.

In each iteration one genetic operator is randomly selected.
Then required amount of individuals for the operation is selected
by individual selection mechanism described above (one or two
individuals for our genetic operators).
And those selected individuals are used as input for selected
genetic operator which produces some new individuals.
Those new individuals are inserted into $pop_{t+1}$.

This process continues until $pop_{t+1}$ is filled with
$popSize$ individuals.  

Selection of genetic operation in each operation is 
controlled by probabilities for each genetic operator.

Koza in \cite{koza92} uses as default probabilities those values:

\begin{itemize}
	\item \textit{Crossover}    : $70\%$
	\item \textit{Reproduction} : $30\%$
	\item \textit{Mutation}     :  $0\%$
\end{itemize}



\newpage
\subsection{GP algorithm in pseudocode}

Bellow is described GP algorithm in pseudocode.
Inputs are:

\begin{itemize}
	\item \textit{fitness} - Fitness function.
	\item \textit{TuF} - Building blocks accompanied with an  	
	      information about implementations and argument numbers.
	\item \textit{popSize} - Population size.
	\item \textit{numGens} - Number of generations.
	\item \textit{probabs} - Genetic operators probabilities.
\end{itemize} 

\Pseudokod{GP(fitness,TuF,popSize,numGens,probabs)}{
	$gen \leftarrow$ 0 \;
	$pop \leftarrow generateInitialPopuletion( TuF ) $ \;
	($popWithF,terminate,best) \leftarrow$ 
	evaluate($fitness$, $TuF$, $pop$)\; 	
	
	\While{ $gen < numGens$ $\wedge$ $\neg terminate$  }{
  	
	
	$newPop \leftarrow$ empty population \;
	$newPop$.insert( $best$ )\;
	$i \leftarrow 1$ \;
	
	\While{ $i < popSize$ }{
		$op \leftarrow probabilisticallySelectOperation(probabs)$ \;		
		\Switch{op}{
			\Case{Crossover}{
				$parent1 \leftarrow$ selection( $popWithF$ ) \;
				$parent2 \leftarrow$ selection( $popWithF$ ) \;
				($child1$,$child2$) = crossover( $parent1$ , $parent2$ )\;
				$newPop$.insert( $child1$ ) \;
				$newPop$.insert( $child2$ ) \;
				$i \leftarrow i + 2$ \;
			}
			\Case{Reproduction}{
				$indiv \leftarrow$ selection( $popWithF$ ) \;
				$newPop$.insert( $indiv$ ) \;
				$i \leftarrow i + 1$ \;
			}
			\Case{Mutation}{
				$indiv \leftarrow$ selection( $popWithF$ ) \;
				$mutant \leftarrow$ mutate( $indiv$ , $TuF$ ) \;
				$newPop$.insert( $mutant$ ) \;
				$i \leftarrow i + 1$ \;			
			}		
		}
	}
	
	$pop \leftarrow newPop$  \;
	($popWithF,terminate,best) \leftarrow$ 
	evaluate($fitness$, $TuF$, $pop$)\;
	$gen \leftarrow gen + 1$ \; 
 }
 \Return pop \;
}

In order to clarify the code let us describe in greater detail inputs and
contained procedures
generateInitialPopuletion(),
evaluate(),
probabilisticallySelectOperation(),
selection(),
crossover() 
and mutation().

\textbf{TODO mention best preservation and same popSize checking. }




...\\\
\subsection{TODO}
	\begin{itemize} 
		\item TALK ABOUT GP is part of EA etc. and maybe define the GP by defining EA and then
		      specifying the differences or something like that...    
		\item History, citations, etc ....
		\item ten algoritmus v kozovi dělá "Designate Result" já tam vracim poslední populaci
	\end{itemize}	  


\newpage		
\section{Lambda term}
\label{deflam}
	
	Let $V$ be set of {\it variable names}.  \\* 
	Let $C$ be set of {\it constant names}.	 \\*		
	Then $\Lambda$ is set of {\it \lterms} inductively defined as follows:
	
	\begin{align*}
		 x   \in V \cup C          &\Rightarrow     x   \in \Lambda \\
		 M,N \in \Lambda           &\Rightarrow ( M N ) \in \Lambda \\
		 x   \in V , M \in \Lambda &\Rightarrow ( \lambda x . M ) \in \Lambda 
	\end{align*} 

	\textbf{TODO} 
	\begin{itemize} 
		\item TALK ABOUT "parenthesis" conventions (and packing of lambda abstractions).
		\item BETTER SPECIFICATION $V$ is infinite spočetná (?countable)
	\end{itemize}
	
\section{Type}
\label{deftype}

	Let $A$ be set of {\it atomic type names}. \\*
	Then $\mathbb{T}$ is set of {\it types} inductively defined as follows:
	
	\begin{align*}
	\alpha      \in A          &\Rightarrow     \alpha   \in \mathbb{T} \\
	\sigma,\tau \in \mathbb{T} &\Rightarrow ( \sigma \rightarrow  \tau ) \in \mathbb{T} 
	\end{align*} 

\textbf{TODO} 
\begin{itemize}
	\item TALK ABOUT $\tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$ 
	\item TALK ABOUT arrow/parenthesis conventions. 
\end{itemize}
	
	
\section{Statement of a form $M : \sigma$}

	Let $\Lambda$ be set of {\it \lterms}. \\*
	Let $\mathbb{T}$ be set of {\it types}.       \\*
	A {\it statement} $M : \sigma$ is a pair $(M,\sigma) \in \Lambda \times \mathbb{T}$. \\*
	$M : \sigma$ is vocalized as {\it "$M$ has type $\sigma$"}.\footnote{ 
	$M : \sigma$ can be also imagined as $M \in \sigma$ } \\*
	The type $\sigma$ is the {\it predicate} and the term $M$ is the
	{\it subject} of the statement.  
	
\section{Context}

	Let $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right)$. 
	($\Gamma$ is a set of {\it statements} of a form $M : \sigma$.)	\\*
	Then $\Gamma$ is {\it context} if it obeys following 
	conditions\footnote{
	The $\pi_1$ corresponds to the projection of the first component of the Cartesian product.
	}:
	\begin{align*}
		 \forall (x,\sigma) \in \Gamma &: x \in V \cup C \\
		 \forall s_1,s_2 \in \Gamma &: s_1 \neq s_2 \Rightarrow \pi_1(s_1) \neq \pi_1(s_2)
    \end{align*}
    
	In other words context is a set of statements with distinct variables or constants as subjects.
	\\\\
	\textbf{TODO:} TALK ABOUT Context represents library/building blocks.
	
	
	
\section{Statement of a form \GMS}

	By writing \GMS we say 
	{\it statement $M : \sigma$ is derivable from context $\Gamma$ }.

	We construct valid statements of form \GMS by using inference rules.
	
		
\section{Inference rule}		
	
	Basically speaking, inference rules are used for deriving statements of a form 
	\GMS from yet derived statements of such a form.
	Those inference rules are written in the following form:
	
	\begin{equation*}
		\frac{\Gamma_1 \vdash M_1 : \sigma_1 \qquad
			  \Gamma_2 \vdash M_2 : \sigma_2 \quad
			  \dotsm \quad
		      \Gamma_n \vdash M_n : \sigma_n}
		     {\Gamma_{n+1} \vdash M_{n+1} : \sigma_{n+1}}
	\end{equation*}	
	
	Suppose we have yet derived statements 
	$\Gamma_1 \vdash M_1 : \sigma_1 ,
	 \Gamma_2 \vdash M_2 : \sigma_2 ,
	 \dots ,
	 \Gamma_n \vdash M_n : \sigma_n$. 
	It allows as to use the inference rule to derive statement
	\mbox{ $\Gamma_{n+1} \vdash M_{n+1} : \sigma_{n+1}$ }.
	 
	For deriving statements including types of a form 
	$(\sigma \rightarrow \tau)$ are essential those two 
	inference rules:
	
	\begin{equation*}
		\frac{\Gamma \vdash M : \sigma \rightarrow \tau \qquad
			  \Gamma \vdash N : \sigma }
		     {\Gamma \vdash (M N) : \tau }
	\end{equation*}	
	
	\begin{equation*}
		\frac{\Gamma \cup \{ ( x,\sigma ) \} \vdash M : \tau }
		     {\Gamma \vdash (\lambda x . M) : \sigma \rightarrow \tau }
	\end{equation*}		 
	 
	This kind of inference rules allows us to derive new statements from yet derived statements, but 
	what if we do not have any statement yet? 
	For this purpose we have other kinds of inference rules such as {\it axiom} inference rule:   
	
	\begin{equation*}
		\frac{( x , \sigma )  \in \Gamma}
		     {\Gamma \vdash x : \sigma}
	\end{equation*}	
	
	\Lets consider an example statement of a form \GMS :
	
	\[
		\{\} \vdash (\lambda f . (\lambda x . (f x) )) : 
		(\sigma \rightarrow \tau) \rightarrow ( \sigma \rightarrow \tau ) 
	\]
		
	This statement is derived as follows: 
	
	\begin{equation*}
	\dfrac{
		\dfrac{ (f,\sigma \rightarrow \tau) \in \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \}  }
		     { \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash f : \sigma \rightarrow \tau }
		\qquad
		\dfrac{ (x,\sigma) \in \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \}  }
		     { \{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash x : \sigma }
		 }
		 {
			\dfrac{		 	
		 		\{ (f,\sigma \rightarrow \tau) , (x,\sigma)  \} \vdash (f x) : \tau
		 	}{
				\dfrac{\{ (f,\sigma \rightarrow \tau) \} \vdash (\lambda x . (f x) ) : 
				\sigma \rightarrow \tau}
				{ \{ \} \vdash (\lambda f . (\lambda x . (f x) ) ) 
				  : (\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau) }
		 	}
		 }
	\end{equation*}		
	
\section{Term generating grammar}

Inference rules are good for deriving statements of a form \GMS, but our
goal is slightly different; we would like to generate many \lterms M for a given type 
$\sigma$ and context $\Gamma$.

Our approach will be to take each inference rule and transform it to a rule of term generating
grammar. With this term generating grammar it will be much easier to reason about generating 
\lterms.
	
It won't be a grammar in classical sense because we will be operating with infinite sets of
nonterminal symbols and rules. \footnote{TODO : mention terminal symbols - situation around 
variables and their construction with ' symbol.}

Let $Non = Type \times Context $ be our {\it nonterminal} set. 
So for every $i \in Non$ is $i = (\sigma_i , \Gamma_i )$.

\Lets consider each relevant inference rule and its corresponding grammar rule.

First inference rule is {\it implication elimination} also known as 
{\it modus ponens}: 
\[
	\frac{\Gamma \vdash M : \sigma \rightarrow \tau \qquad
		  \Gamma \vdash N : \sigma }
	     {\Gamma \vdash (M N) : \tau }
\]
\\
For every $\sigma, \tau \in \mathbb{T}$ and for every {\it context} 
$\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right)$ there is a grammar rule of a form\footnote{ 
Terminal symbols for parenthesis and normally {\it space} now \textvisiblespace \quad (for {\it function application} operator) are visually highlighted. }: 
\[	
	( \tau , \Gamma )  \longmapsto
	\bigg( ( \sigma \rightarrow \tau , \Gamma ) 
	  \mbox{ \Vtextvisiblespace[1em] } ( \sigma , \Gamma ) \bigg)
\]
\\

Second inference rule is {\it implication introduction}: 
\[
	\frac{\Gamma \cup \{ ( x,\sigma ) \} \vdash M : \tau }
	     {\Gamma \vdash (\lambda x . M) : \sigma \rightarrow \tau }
\]
\\
$\forall \sigma, \tau \in \mathbb{T}$ 
$\forall${\it context} $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right) $ 
$\forall x \in V $ such that there is no $(x,\rho) \in \Gamma$ 
there is a grammar rule:
\[ 
	( \sigma \rightarrow \tau , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large $\lambda$ x . }}( \tau , \Gamma \cup \{ (x,\sigma) \} ) \quad \bigg)
\]
\\	

Third inference rule is {\it axiom}: 
\[
		\frac{( x , \sigma )  \in \Gamma}
		     {\Gamma \vdash x : \sigma}
\]
\\
$\forall \sigma \in \mathbb{T}$ 
$\forall${\it context} $\Gamma \in \mathfrak P \left({\Lambda \times  \mathbb{T}}\right) $ 
$\forall x \in V \cup C $ such that $(x,\sigma) \in \Gamma$ 
there is a grammar rule:
\[ 
	( \sigma , \Gamma )  \longmapsto \mbox{ {\Large x}}
\]
\\

We will demonstrate \lterm generation on example. 
Again on $(\lambda f . (\lambda x . (f x) ))$. 
We would like to generate \lterm of a type 
$(\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau)$
with $\Gamma = \{\}$.
\begin{align*}
	& ((\sigma \rightarrow \tau) \rightarrow (\sigma \rightarrow \tau),\{\}) \\ 
	\longmapsto & \Big( \mbox{ {\Large $\lambda$f.}}
	  ( \sigma \rightarrow \tau , \{ (f,\sigma \rightarrow \tau) \} ) 
	~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}
	  	 	( \tau , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) 
		~ \Big)  	 
	~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  ( \sigma \rightarrow \tau , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  ( \sigma , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} )  \Big) 
		~ \Big)  	 
	 ~ \Big)
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  \mbox{ {\Large f}} 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  ( \sigma , \{ (f,\sigma \rightarrow \tau) , (x,\sigma) \} ) \Big) 
		~ \Big)  	 
	~ \Big)		
	\\
	\longmapsto & 
	\Big( \mbox{ {\Large $\lambda$f. }}
		\Big( \mbox{ {\Large $\lambda$x. }}	  	 	
	  	 	\Big( 
	  	 	  \mbox{ {\Large f}} 
			  \mbox{ \Vtextvisiblespace[1em] } 
			  \mbox{{\Large x}} \Big) 
		~ \Big)  	 
	~ \Big)
\end{align*}

\subsection{"Barendregt-like" inference and grammar rules}
\label{barlike}

Inference rule 1: 
\[
	\frac{\Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} \vdash M : \alpha }
	     {\Gamma \vdash (\lambda x_1 \dots x_n . M) : 
	     \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha }
\]
\\
Proof of correctness:
\[
	\dfrac{
		\dfrac
		 {\Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} \vdash M : \alpha}
		 {\dfrac
		   {\Gamma \cup \{ (x_1,\tau_1),\dots,(x_{n-1},\tau_{n-1})\} \cup 
		                \{(x_n,\tau_n) \} \vdash M : \alpha}
		   {\dfrac{\Gamma \cup \{ (x_1,\tau_1),\dots,(x_{n-1},\tau_{n-1})\}  
		                \vdash (\lambda x_n . M) : \tau_n \rightarrow \alpha}
				  { \vdots }		   
		   }
		 }		 
	 }
	     {\Gamma \vdash (\lambda x_1 \dots x_n . M) : 
	     \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha }
\]
\\
... there is a grammar rule:
\[ 
	( \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large 
	$\lambda x_1 \dots x_n .$ 
	}}( \alpha , \Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} ) \quad \bigg)
\]
\\

Inference rule 2: 
\[
	\frac{ (f , \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha ) \in \Gamma \qquad
	       \Gamma \vdash M_1 : \rho_1 \quad
	       \dotsm \quad
	       \Gamma \vdash M_m : \rho_m        
	      }
	     {\Gamma \vdash (f M_1 \dots M_m) : \alpha}
\]
\\
Proof of correctness (\textbf{TODO REPAIR} Conceptually it is ok but there is sazba-bug somewhere): 
\[
   \dfrac
     {\dfrac
      {\dfrac
       {\dfrac         
         {\dfrac  
          {\dfrac
           {\boxed{(f , \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha ) \in \Gamma}}
           {\Gamma \vdash f : \rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha}
           \quad
           \boxed{\Gamma \vdash M_1 : \rho_1} }
          {\Gamma \vdash (f M_1) : \rho_2 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha }
          }{\vdots} 
         \quad 
         \ddots }
       {\Gamma \vdash (f M_1 \dots M_{m-2}) : \rho_{m-1} \rightarrow \rho_m \rightarrow \alpha}
       \quad
       \boxed{\Gamma \vdash M_{m-1} : \rho_{m-1}}  }
      {\Gamma \vdash (f M_1 \dots M_{m-1}) : \rho_m \rightarrow \alpha}       
      \quad 
      \boxed{\Gamma \vdash M_m : \rho_m} }
	 {\Gamma \vdash (f M_1 \dots M_m) : \alpha}
\]
\\
... there is a grammar rule:
\[ 
	( \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large f }}
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_1 , \Gamma )
	  \mbox{ \Vtextvisiblespace[1em] } 
	  \dots
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_m , \Gamma )
	  \quad \bigg)
\]
\\\\
\textbf{TODO} 
\begin{itemize}
	\item SHOW correctness of those inference rules by composing them of 
		  $E^{\rightarrow}$, $I^{\rightarrow}$ and \textit{axiom}.
	\item SHOW more examples of inference rules transformed into grammar rules.
	\item DESCRIBE general algorithm for this transformation.
	\item TALK ABOUT $\tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$ 
	\item TALK ABOUT $\beta \eta$-normal form which is generated by this method.
\end{itemize}



\section{Inhabitation tree}

Now we will introduce \textit{Inhabitation tree}, structure slightly different from
\textit{Inhabitation machine}, which was introduced in \cite{barendregt10} by Henk Barendregt.
We can think about Inhabitation tree as about unfolded Inhabitation machine.
The motivation for using Inhabitation trees is belief that it will help us 
reason about generation of \lterms 
of a given type $\sigma$ and with a given context $\Gamma$.  

\subsection{Definition of Inhabitation tree}

\textit{Inhabitation tree} is a \textit{rooted tree}, possibly infinite. 
It has two types of nodes:

\begin{samepage}
\begin{itemize}
  \item Type nodes   
  			- containing type $\sigma \in \mathbb{T}$ 
  			- aka "OR-node" , Nonterminal-node. 
  \item Symbol nodes 
  			%- containing $ x^{*} \in \mathfrak P \left(V\right) -blobost pač ordered $ or $c \in C$
  			- containing "$\lambda$-head" (nonempty finite sequence of variable names) or constant
  			  name. 
  			- aka "AND-node" , Terminal-node.
\end{itemize}
\end{samepage}

We construct Inhabitation tree for given type $\sigma$ and context $\Gamma$.\\
We will define Inhabitation tree by describing its construction for a given $(\sigma,\Gamma)$.
Notice that it will closely follow the rules from \ref{barlike}:

\begin{itemize}
\item The root of Inhabitation tree for $(\sigma,\Gamma)$ is 
      \textit{type node} with $\sigma$ as type.
\item All \textit{type nodes} have as child nodes only \textit{symbol nodes}. 
\item And all \textit{symbol nodes} have as child nodes only \textit{type nodes}. 
\end{itemize}

\begin{samepage}
Now we will resolve the child nodes of the root node.
There are two cases of $\sigma$ (recall \ref{deftype}): 
\begin{description}
	\item[Atomic type] 
		$\sigma = \alpha $ where $\alpha \in A$. 
	\item[Function type] 
		$\sigma = \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$
		where $n \geq 1, \alpha \in A$.
\end{description}
\end{samepage}


First case \textbf{Atomic type} --- i.e., $\sigma = \alpha$ where $\alpha \in A$:\\
For every $(f,\rho_1 \rightarrow \dots \rightarrow \rho_m \rightarrow \alpha) \in \Gamma$
where $\alpha \in A$ there is a child \textit{symbol node} of the root containing constant name $f$.
This symbol node containing $f$ has $m$ child subtrees corresponding to Inhabitation trees for 
$(\rho_1,\Gamma),\dots,(\rho_n,\Gamma)$.   

~

Compare this case with corresponding grammar rule:
\[ 
	( \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large f }}
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_1 , \Gamma )
	  \mbox{ \Vtextvisiblespace[1em] } 
	  \dots
	  \mbox{ \Vtextvisiblespace[1em] } 
	  ( \rho_m , \Gamma )
	  \quad \bigg)
\]

Second case \textbf{Function type} --- i.e., 
$\sigma = \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha$
where $n~\geq~1, \alpha~\in~A$:\\
For every  $i \in \{1,\dots,n\}$ we create new \textit{variable name} $x_i$ which is not yet included in context $\Gamma$ as variable or constant name.
 
There is one and only one child \textit{symbol node} of the root containing "$\lambda$-head" 
$\lambda x_1 \dots x_n$ which stands for sequence of variable names $(x_1,\dots,x_n)$.
This symbol node containing $\lambda x_1 \dots x_n$
has one and only one child subtree corresponding to Inhabitation trees for 
$(\alpha,\Gamma \cup \{ (x_1,\tau_1) , \dots , (x_n,\tau_n) \})$.   

~

Compare this case with corresponding grammar rule:
\[ 
	( \tau_1 \rightarrow \dots \rightarrow \tau_n \rightarrow \alpha , \Gamma )  \longmapsto
	\bigg( \mbox{ {\Large 
	$\lambda x_1 \dots x_n .$ 
	}}( \alpha , \Gamma \cup \{ (x_1,\tau_1),\dots,(x_n,\tau_n) \} ) \quad \bigg)
\]
~\\
\Lets consider following $(\sigma,\Gamma)$ as a simple example:

\begin{align*}
\sigma =& ~ \mathbb{B} \rightarrow  \mathbb{B} \rightarrow  \mathbb{B} \\ 
\Gamma =& \{ ~ true : \mathbb{B}  \\
        &  , ~ nand :  \mathbb{B} \rightarrow \mathbb{B} \rightarrow \mathbb{B} ~ \}
\end{align*}

This particular $(\sigma,\Gamma)$ results in the following tree:\\

\Tree
[.\text{ $\mathbb{B} \rightarrow \mathbb{B} \rightarrow \mathbb{B}$ }  
	[.\textbf{$\lambda$x_1 x_2 } 
		[.\text{ $\mathbb{B}$ } 
			\textbf{true}  
			[.\textbf{nand} 
				\qroof{ ~~ $\dotsb$ ~~ }.\text{ $\mathbb{B}$ }
				\qroof{ ~~ $\dotsb$ ~~ }.\text{ $\mathbb{B}$ } 
			]
			\textbf{x_1}
			\textbf{x_2}
		]
	]
]

~

Second example features our well known example:

\begin{align*}
\sigma =& ~ (\sigma \rightarrow \tau) \rightarrow \sigma \rightarrow \tau \\ 
\Gamma =& \{ \}
\end{align*}

Which results in following tree:

\Tree
[.\text{ $(\sigma \rightarrow \tau) \rightarrow \sigma \rightarrow \tau $ } 
	[.\textbf{$\lambda$ f x }	
		[.\text{ $\tau$ }		
			[.\textbf{f} 
				[.\text{ $\delta$ }
					\textbf{x}					
				]
			]
		]
	]
] 


\subsection{And-or tree and searching in Inhabitation tree}
\Lets consider following definition of 
\textit{And-or tree}\footnote{
\textbf{TODO}: Mention that on WIKI there is more general definition, but 
for our purposes is this one sufficient.}:

\textit{And-or tree} is a rooted tree where each node is labeled as either \textit{and-node} 
or\footnote{xor} \textit{or-node}.

By \textit{solving} And-or tree $T$ we mean finding $T'$
subtree of $T$ such that it follows these conditions: 
\begin{itemize}
	\item The root of $T'$ is the root of $T$.
	\item Each \textit{and-node} in $T'$ has all the child nodes as in $T$.
	\item Each \textit{or-node}  in $T'$ has precisely one child 
	      node.\footnote{\textbf{TODO}: MENTION why precisely one 
	      and not at least one ..or CHANGE the def. }   
\end{itemize}
~
\Lets now consider following labeling of Inhabitation tree: 

\begin{itemize}
  \item \textbf{Type nodes}   are labeled as \textbf{or-nodes}.   
  \item \textbf{Symbol nodes} are labeled as \textbf{and-nodes}.
\end{itemize}

This labeling has following justification: 

Selection of exactly one
child node in \textit{type node} corresponds to selection of exactly one
grammar rule in order to rewrite nonterminal symbol.  

Selection of all the child nodes in \textit{symbol node} corresponds to 
rewriting all the nonterminal symbols in string that is being generated.  

The motivation for defining \textit{solving} of a And-or tree the way we did is that
a found tree $T'$ corresponds to generated \lterm. 
In order to understand this correspondence let's now talk about various tree representations
of \lterms.

\subsection{Tree representations of \lterms}

From the definition of \lterm (\ref{deflam}) we can straightforwardly derive 
the classical tree representation for \lterms. Term M is translated into tree $T[M]$ by following rules:

\begin{itemize}
	\item $x \in V \cup C$ translates into \textit{leaf} $x$.
	\item $(M N)$ translates into tree\\
		\Tree
			[.@	
		 		\text{$T[M]$}
		 		\text{$T[N]$}		 			
			] 
	\item $\lambda x . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x$}	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

We can enhance this representation by compressing consecutive lambda abstractions into one
tree node like this: 

\begin{itemize}
	\item $\lambda x_1 \dots x_n . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x_1 \dots x_n$ }	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

As this representation comes directly from definition it is evident 
that it covers all possible \lterms.

For representing expressions as trees it is however more common use a little different
representation. It will also be the representation suitable for showing 
that \textit{solving} Inhabitation tree generates wanted \lterm.

\begin{itemize}
    \item $x \in V \cup C$ translates into \textit{leaf} $x$.
	\item $(f M_1 M_2 \dots M_n)$ where $f \in V \cup C, n \geq 1$ translates into tree\\
		\Tree
			[.f	
		 		\text{$T[M_1]$}
		 		\text{$T[M_2]$}
		 		\text{$\dots$}
		 		\text{$T[M_n]$}		 				 			
			] 
	\item $\lambda x_1 \dots x_n . M$ translates into tree\\
	 	\Tree
			[.\text{$\lambda x_1 \dots x_n$ }	
		 	 	\text{$T[M]$}	
			] 
\end{itemize}

Notice that this representation does not cover all \lterms, 
e.g. $(\lambda x.x) y$ is not expressible in it. But it does not bother us.  
\\\\
\Lets now consider representation for \textit{typed \lterms}.
Straightforward approach would be to add to each node a type entry which 
would be the type of the \lterm corresponding to subtree having this
node as the root node. 

Approach more suitable for our purpose is to add a special type node above each node.
More specifically:

\Lets consider tree $t$ corresponding to a \lterm of a type
$\sigma$ with root $r$ and subtrees $s_1 , \dots , s_n$. 
Then corresponding tree $TT[t]$ for typed \lterm is 
obtained from the tree $t$ as follows:  

\begin{equation*}
\mbox{ 
TT[
\Tree
	[.r 	
	  	  \text{$s_1$}
		  \text{$s_2$}
		  \text{$\dots$}
		  \text{$s_n$}
	] 
}]=
\mbox{
\Tree
	[.\text{$\sigma$ }
	    [.r 	
	  	  \text{$TT[s_1]$}
		  \text{$TT[s_2]$}
		  \text{$\dots$}
		  \text{$TT[s_n]$}
		]	  	
	] 
}
\end{equation*}
	  	
Now we can finally put the pieces together. 
Every solution to a Inhabitation tree has this just described tree form of a typed \lterm. 
 

~\\
\textbf{TODO} 
\begin{itemize}
\item EXAMPLES of tree representations of \lterms  
\item TALK (more?) ABOUT "Barendregt-like" subsection \ref{barlike}\\
		Things about $\beta\eta$ normal form, etc.   
\item DESCRIBE Inhabitation Machine... 
\end{itemize}
		

\subsection{Our approach to \textit{solving} Inhabitation tree}


The main design choice behind our approach to solving inhabitation trees
is ability to be variable enough to enable choice between 
\textit{systematic} way of generating terms 
and \textit{classical-GP-like} way of generating terms 
by choice of simple search strategy.\\

\Lets explain what is meant by \textit{systematic} and \textit{classical-GP-like}. \\

\textit{Systematic} way of solving inhabitation tree corresponds to
generating terms in order from smallest to largest in number of symbols and \lheads.
That means minimizing number of and-nodes in and-or-tree view of point on inhabitation tree.
But since inhabitation tree is a special kind of and-or-tree with alternating layers of 
and-nodes (symbols and \lheads) and or-nodes (types) it is also minimizing number of 
size of whole inhabitation/and-or tree. \\

\textit{Classical-GP-like} ... \textbf{TODO}

\subsubsection{A* algorithm}

A* is a general informed search algorithm used for finding shortest path in a state space.
According to \cite{AIAMA} A* is the most widely known form of best-first search.








\section{Conversion to SKI combinators}





\chapter{ Designed system }	
	\section{Top level view}
		\subsection{Comments about main source files}
			\subsubsection{ Eva.hs }
			\subsubsection{ GP\_{}Core.hs }
	\section{Term generating}
	\section{Crossover}
		\subsection{Finding same types}
		\subsection{Two basic options}
		Resolve problems with free variables or avoid variables completely. 
		
	\section{Mutation}
		\subsection{Using term generation}


\chapter{Problems}
	In this section will be presented usage of the system in order to solve specific problems.
		
	
		\section{Even Parity Problem}
		\section{Big Context}
		\section{Fly}
		\section{Simple Symbolic Regression}
		\section{Artificial Ant}
		\section{Boolean Alternate}
	
\chapter{Ideas yet not implemented}

\section{Roadmap}
\section{Tree ants}
\section{[Propojení těch dvou barandrechtskejch odvozovacích pravidel do jedinýho]}
\section{[Chytřejší heuristika pro A* která si to předpočítá na $\overline{\Gamma}$ ]}





%\chapter{Conclusion}
\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}	
	

\begin{thebibliography}{9}


\bibitem{koza92}

  John R. Koza,
  \emph{Genetic Programming: On the Programming of Computers by Means of Natural Selection}.
  MIT Press, Cambridge, MA,
  1992. 

\bibitem{barendregt10}

  Henk Barendregt, Wil Dekkers, Richard Statman,
  \emph{Lambda Calculus With Types}.
  Cambridge University Press,
  2010. \\
  \url{http://www.cs.ru.nl/~henk/book.pdf}


\bibitem{AIAMA}

	Stuart J. Russell, Peter Norvig,
	\emph{Artificial Intelligence: A Modern Approach}.
	Pearson Education,
	2003. 

\end{thebibliography}

	
	
\end{document}
